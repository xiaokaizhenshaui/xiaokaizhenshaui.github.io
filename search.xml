<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/2022/03/10/Kafka%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0(%E4%B8%80)/Kafkawindow%E7%8E%AF%E5%A2%83%E9%80%82%E9%85%8D/"/>
      <url>/2022/03/10/Kafka%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0(%E4%B8%80)/Kafkawindow%E7%8E%AF%E5%A2%83%E9%80%82%E9%85%8D/</url>
      
        <content type="html"><![CDATA[<h1 align="center" style="color:skyblue">Kafka入门学习</h1><h2 id="Kafka预备材料"><a href="#Kafka预备材料" class="headerlink" title="Kafka预备材料"></a>Kafka预备材料</h2><p>kafka需要在zookeeper基础上运行，则需要准备zookeeper-3.4.6，kafka_2.13.3-3.1.0.tgz</p><h2 id="zookeeper启动"><a href="#zookeeper启动" class="headerlink" title="zookeeper启动"></a>zookeeper启动</h2><p>zookeeper版本暂时没有定位</p><ol><li><p>解压打开文件conf目录，将zoo_sample.cfg重命名成zoo.cfg</p></li><li><p>从文本编辑器里打开zoo.cfg，把dataDir的值改成“E:\develop\zookeeper-3.4.6\zookeeper-3.4.6\data”</p></li><li><p>添加环境变量</p><ol><li>ZOOKEEPER_HOME: E:\develop\zookeeper-3.4.6\zookeeper-3.4.6</li><li>Path: 在现有的值后面添加 “%ZOOKEEPER_HOME%\bin”</li></ol></li><li><p>运行Zookeeper</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkserver</span><br></pre></td></tr></table></figure><p>效果：</p><p><img src="zkserver.png" alt="zkserver"></p></li></ol><h2 id="安装运行Kafka"><a href="#安装运行Kafka" class="headerlink" title="安装运行Kafka"></a>安装运行Kafka</h2><p>3.1 下载安装文件： <a href="http://kafka.apache.org/downloads.html">http://kafka.apache.org/downloads.html</a></p><p><img src="kafka.png" alt="image-20220310165512508"></p><p>3.2 解压文件（本文解压到 G:\kafka_2.11-0.10.0.1）</p><p>3.3  打开G:\kafka_2.11-0.10.0.1\config</p><p>3.4  从文本编辑器里打开 server.properties</p><p>3.5  把 log.dirs的值改成 “G:\kafka_2.11-0.10.0.1\kafka-logs”</p><p>3.6  打开cmd</p><p>3.7  进入kafka文件目录: cd /d G:\kafka_2.11-0.10.0.1\</p><p>3.8  输入并执行以打开kafka:</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.\bin\windows\kafka-server-<span class="built_in">start</span>.bat .\config\server.properties</span><br></pre></td></tr></table></figure><!--此时可能遇到报错usage，可把kafka文件放置在根目录下或者缩短cmd的目录前缀--><p><img src="start-bat.png" alt="image-20220310165845500"></p><h2 id="操作启动"><a href="#操作启动" class="headerlink" title="操作启动"></a>操作启动</h2><ol><li><p>创建topics</p></li><li><p>topics=xiaokai</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.bat --create --zookeeper localhost:<span class="number">2181</span> --replication-factor <span class="number">1</span> --partitions <span class="number">1</span> --topic xiaokai</span><br></pre></td></tr></table></figure><p>可能会报错，Exception in thread “main“ joptsimple.UnrecognizedOptionException: zookeeper is not a recognizedException in thread “main“ joptsimple.UnrecognizedOptionException: zookeeper is not a recognized</p><p>是因为2.2版本以后不再需要Zookeeper链接字符串，仅需要–bootstrap-server localhost:9092来替代- -zookeeper localhost:2181</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.bat --create --bootstrap-server localhost:<span class="number">9092</span> --replication-factor <span class="number">1</span> --partitions <span class="number">1</span> --topic txiaokai</span><br></pre></td></tr></table></figure><p><img src="topics.png" alt="image-20220310170617264"></p><p>检查创建的topics</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.bat --list --bootstrap-server localhost:<span class="number">9092</span></span><br></pre></td></tr></table></figure><p><img src="check.png" alt="image-20220310170713975"></p><p>即为创建成功</p></li><li><p>打开一个producer</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-producer.bat --broker-list localhost:<span class="number">9092</span> --topic xiaokai</span><br></pre></td></tr></table></figure></li><li><p>打开一个consumer</p><p>同时启动，不需要关闭生产者</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.bat --bootstrap-server localhost:<span class="number">9092</span> --topic xiaokai</span><br></pre></td></tr></table></figure><p><img src="%E6%95%88%E6%9E%9C.png" alt="image-20220310171026490"></p></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2022/01/17/JDK8-JDK17%E4%B8%AA%E7%89%88%E6%9C%AC%E9%87%8D%E8%A6%81%E7%89%B9%E6%80%A7/"/>
      <url>/2022/01/17/JDK8-JDK17%E4%B8%AA%E7%89%88%E6%9C%AC%E9%87%8D%E8%A6%81%E7%89%B9%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<h1 id="JDK8-JDK17个版本重要特性"><a href="#JDK8-JDK17个版本重要特性" class="headerlink" title="JDK8-JDK17个版本重要特性"></a>JDK8-JDK17个版本重要特性</h1><h2 id="JDK8新特性（2014年初）（LTS版本）"><a href="#JDK8新特性（2014年初）（LTS版本）" class="headerlink" title="JDK8新特性（2014年初）（LTS版本）"></a>JDK8新特性（2014年初）（LTS版本）</h2><ol><li>Lambda表达式</li><li>函数式编程</li><li>接口可以添加默认方法和静态方法，也就是定义不需要实现类实现的方法</li><li>方法引用</li><li>重复注解，同一个注解可以使用多次</li><li>引入Optional来避免空指针</li><li>引入Streams相关的API</li><li>引入新的Date/Time相关的API</li><li>新增jdeps命令行，来分析类、目录、jar包的类依赖层级关系</li><li>JVM使用MetaSpace代替了永久代（PermGen Space）</li></ol><p><strong>重要特性：Lambda表达式、函数式接口、方法引用、Stream流式API、采用MetaSpace代替了永久代（PermGen Space）</strong></p><h2 id="JDK9新特性（2017年9月）"><a href="#JDK9新特性（2017年9月）" class="headerlink" title="JDK9新特性（2017年9月）"></a>JDK9新特性（2017年9月）</h2><ol><li>接口方法可以使用private来修饰</li><li>设置G1为JVM默认垃圾收集器</li><li>支持http2.0和websocket的API</li></ol><p><strong>重要特性：主要是API的优化，如支持HTTP2的Client API、JVM采用G1为默认垃圾收集器</strong></p><h2 id="JDK10新特性（2018年3月）"><a href="#JDK10新特性（2018年3月）" class="headerlink" title="JDK10新特性（2018年3月）"></a>JDK10新特性（2018年3月）</h2><ol><li>局部变量类型推断，类似JS可以通过var来修饰局部变量，编译之后会推断出值的真实类型</li><li>并行Full GC，来优化G1的延迟</li><li>允许在不执行全局VM安全点的情况下执行线程回调，可以停止单个线程，而不需要停止所有线程或不停止线程</li></ol><p><strong>重要特性：通过var关键字实现局部变量类型推断，使Java语言变成弱类型语言、JVM的G1垃圾回收由单线程改成多线程并行处理，降低G1的停顿时间</strong></p><h2 id="JDK11新特性（2018年9月）（LTS版本）"><a href="#JDK11新特性（2018年9月）（LTS版本）" class="headerlink" title="JDK11新特性（2018年9月）（LTS版本）"></a>JDK11新特性（2018年9月）（LTS版本）</h2><ol><li>ZGC，ZGC可以看做是G1之上更细粒度的内存管理策略。由于内存的不断分配回收会产生大量的内存碎片空间，因此需要整理策略防止内存空间碎片化，在整理期间需要将对于内存引用的线程逻辑暂停，这个过程被称为”Stop the world”。只有当整理完成后，线程逻辑才可以继续运行。（并行回收）</li><li>Flight Recorder（飞行记录器），基于OS、JVM和JDK的事件产生的数据收集框架</li><li>对Stream、Optional、集合API进行增强</li></ol><p><strong>重要特性：对于JDK9和JDK10的完善，主要是对于Stream、集合等API的增强、新增ZGC垃圾收集器</strong></p><h2 id="JDK12新特性（2019年3月）"><a href="#JDK12新特性（2019年3月）" class="headerlink" title="JDK12新特性（2019年3月）"></a>JDK12新特性（2019年3月）</h2><ol><li>Shenandoah GC，新增的GC算法</li><li>switch 表达式语法扩展，可以有返回值</li><li>G1收集器的优化，将GC的垃圾分为强制部分和可选部分，强制部分会被回收，可选部分可能不会被回收，提高GC的效率</li></ol><p><strong>重要特性：switch表达式语法扩展、G1收集器优化、新增Shenandoah GC垃圾回收算法</strong></p><h2 id="JDK13新特性（2019年9月）"><a href="#JDK13新特性（2019年9月）" class="headerlink" title="JDK13新特性（2019年9月）"></a>JDK13新特性（2019年9月）</h2><ol><li>Socket的底层实现优化，引入了NIO；</li><li>switch表达式增加yield关键字用于返回结果，作用类似于return，如果没有返回结果则使用break；</li><li>ZGC优化，将标记长时间空闲的堆内存空间返还给操作系统，保证堆大小不会小于配置的最小堆内存大小，如果堆最大和最小内存大小设置一样，则不会释放内存还给操作系统；</li><li>引入了文本块，可以使用”””三个双引号表示文本块，文本块内部就不需要使用换行的转义字符；</li></ol><p><strong>重要特性：ZGC优化，释放内存还给操作系统、socket底层实现引入NIO</strong></p><h2 id="JDK14新特性（2020年3月）"><a href="#JDK14新特性（2020年3月）" class="headerlink" title="JDK14新特性（2020年3月）"></a>JDK14新特性（2020年3月）</h2><ol><li>instanceof类型匹配语法简化，可以直接给对象赋值，如if(obj instanceof String str),如果obj是字符串类型则直接赋值给了str变量；</li><li>引入record类，类似于枚举类型，可以向Lombok一样自动生成构造器、equals、getter等方法；</li><li>NullPointerException打印优化，打印具体哪个方法抛的空指针异常，避免同一行代码多个函数调用时无法判断具体是哪个函数抛异常的困扰，方便异常排查；</li></ol><h2 id="JDK15新特性（2020年9月）"><a href="#JDK15新特性（2020年9月）" class="headerlink" title="JDK15新特性（2020年9月）"></a>JDK15新特性（2020年9月）</h2><ol><li>隐藏类 hidden class；</li><li>密封类 sealed class，通过sealed关键字修饰抽象类限定只允许指定的子类才可以实现或继承抽象类，避免抽象类被滥用；</li></ol><h2 id="JDK16新特性（2021年3月）"><a href="#JDK16新特性（2021年3月）" class="headerlink" title="JDK16新特性（2021年3月）"></a>JDK16新特性（2021年3月）</h2><ol><li>ZGC性能优化</li><li>instanceof模式匹配</li><li>record的引入</li></ol><p>JDK16相当于是将JDK14、JDK15的一些特性进行了正式引入</p><h2 id="JDK17新特性（2021年9月）（LTS版本）"><a href="#JDK17新特性（2021年9月）（LTS版本）" class="headerlink" title="JDK17新特性（2021年9月）（LTS版本）"></a>JDK17新特性（2021年9月）（LTS版本）</h2><ol><li> 正式引入密封类sealed class，限制抽象类的实现；</li><li>统一日志异步刷新，先将日志写入缓存，然后再异步刷新；</li></ol><p>虽然JDK17也是一个LTS版本，但是并没有像JDK8和JDK11一样引入比较突出的特性，主要是对前几个版本的整合和完善</p><h1 id="CMS垃圾回收机制"><a href="#CMS垃圾回收机制" class="headerlink" title="CMS垃圾回收机制:"></a>CMS垃圾回收机制:</h1><p>CMS全称 ConcurrentMarkSweep，是一款并发的、使用标记-清除算法的垃圾回收器， 如果老年代使用CMS垃圾回收器，需要添加虚拟机参数-“XX:+UseConcMarkSweepGC”。</p><p>使用场景：</p><p>GC过程短暂停，适合对时延要求较高的服务，用户线程不允许长时间的停顿。</p><p>缺点：</p><p>服务长时间运行，造成严重的内存碎片化。 另外，算法实现比较复杂（如果也算缺点的话）</p><p>实现机制</p><p>根据GC的触发机制分为：周期性Old GC（被动）和主动Old GC，纯属个人理解，实在不知道怎么分才好。</p><p>周期性Old GC</p><p>周期性Old GC，执行的逻辑也叫 BackgroundCollect，对老年代进行回收，在GC日志中比较常见，由后台线程ConcurrentMarkSweepThread循环判断（默认2s）是否需要触发。</p><h1 id="G1垃圾收集器（并发是核心）"><a href="#G1垃圾收集器（并发是核心）" class="headerlink" title="G1垃圾收集器（并发是核心）:"></a>G1垃圾收集器（并发是核心）:</h1><p>​    Garbage First，<strong>优先处理那些垃圾多的内存块的意思</strong>。一般的垃圾回收器把内存分成三类: Eden(E), Suvivor(S)和Old(O), 其中Eden和Survivor都属于年轻代，Old属于老年代，新对象始终分配在Eden里面，熬过一次垃圾回收的对象就被移动到Survisor区了，经过数次垃圾回收之后还活着的对象会被移到Old区。</p><p>跟其它垃圾回收器不一样的是：<strong>G1虽然也把内存分成了这三大类，但是在G1里面这三大类不是泾渭分明的三大块内存，G1把内存划分成很多小块, 每个小块会被标记为E/S/O中的一个，可以前面一个是Eden后面一个就变成Survivor了。</strong></p><p>同优秀的CMS垃圾回收器一样，G1也是关注最小时延的垃圾回收器，也同样适合大尺寸堆内存的垃圾收集。G1最大的特点是引入分区的思路，弱化了分代的概念，合理利用垃圾收集各个周期的资源，解决了其他收集器甚至CMS的众多缺陷。</p><p>​    在G1中，有一种特殊的区域，叫Humongous区域。 如果一个对象占用的空间超过了分区容量50%以上，G1收集器就认为这是一个巨型对象。这些巨型对象，默认直接会被分配在年老代，但是如果它是一个短期存在的巨型对象，就会对垃圾收集器造成负面影响。为了解决这个问题，G1划分了一个Humongous区，它用来专门存放巨型对象。如果一个H区装不下一个巨型对象，那么G1会寻找连续的H分区来存储。为了能找到连续的H区，有时候不得不启动Full GC。在java 8中，持久代也移动到了普通的堆内存空间中，改为元空间。</p><p>这么做给G1带来了很大的好处，由于把三块内存变成了几百块内存，内存块的粒度变小了，从而可以垃圾回收工作更彻底的并行化。</p><p>G1的并行收集做得特别好，我们第一次听到并行收集应该是CMS(Concurrent Mark &amp; Sweep)垃圾回收算法, 但是CMS的并行收集也只是在收集老年代能够起效，而在回收年轻代的时候CMS是要暂停整个应用的(Stop-the-world)。而G1整个收集全程几乎都是并行的，它回收的大致过程是这样的:</p><ul><li>在垃圾回收的最开始有一个短暂的时间段(Inital Mark)会停止应用(stop-the-world)</li><li>然后应用继续运行，同时G1开始Concurrent Mark</li><li>再次停止应用，来一个Final Mark (stop-the-world)</li><li>最后根据Garbage First的原则，选择一些内存块进行回收。(stop-the-world)</li></ul><p>由于它高度的并行化，因此它在应用停止时间(Stop-the-world)这个指标上比其它的GC算法都要好。</p><p><strong>G1的另一个显著特点他能够让用户设置应用的暂停时间，为什么G1能做到这一点呢？也许你已经注意到了，G1回收的第4步，它是“选择一些内存块”，而不是整代内存来回收，这是G1跟其它GC非常不同的一点，其它GC每次回收都会回收整个Generation的内存(Eden, Old), 而回收内存所需的时间就取决于内存的大小，以及实际垃圾的多少，所以垃圾回收时间是不可控的；而G1每次并不会回收整代内存，到底回收多少内存就看用户配置的暂停时间，配置的时间短就少回收点，配置的时间长就多回收点，伸缩自如。 (阿里面试)</strong></p><p>由于内存被分成了很多小块，又带来了另外好处，由于内存块比较小，进行内存压缩整理的代价都比较小，相比其它GC算法，可以有效的规避内存碎片的问题。</p><p>说了G1的这么多好处，也该说说G1的坏处了，如果应用的内存非常吃紧，对内存进行部分回收根本不够，始终要进行整个Heap的回收，那么G1要做的工作量就一点也不会比其它垃圾回收器少，而且因为本身算法复杂了一点，可能比其它回收器还要差。因此G1比较适合内存稍大一点的应用(一般来说至少4G以上)，小内存的应用还是用传统的垃圾回收器比如CMS比较合适。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>G1通过在垃圾回收领域应用并行化的策略，把几块大内存块的回收问题，变成了几百块小内存的回收问题，使得回收算法可以高度并行化，同时也因为分成很多小块，使得垃圾回收的单位变成了小块内存，而不是整代内存，使得用户可能对回收时间进行配置，垃圾回收变得可以预期了。</p><p>分而治之、化整为零这些朴素的架构思想往往是很多牛叉技术产品背后的思想根源。</p><p><strong>G1最显著于CMS的，在于它对空间做了整理，这样减少了空间的碎片化</strong>。G1 相对于 CMS 只有在大堆的场景下才有优势，CMS 比较伤的是 remark 阶段，如果堆太大需要扫描的东西太多。整堆扫描，部分收集。</p><h1 id="ZGC垃圾收集器："><a href="#ZGC垃圾收集器：" class="headerlink" title="ZGC垃圾收集器："></a>ZGC垃圾收集器：</h1><p>ZGC时Java进程占用三倍内存问题：由于ZGC着色指针把内存空间映射了3个虚拟地址，使得TOP/PS等命令查看占用内存时看到Java进程占用内存过大。此问题不影响操作系统，但是会影响到监控运维工具，需要注意。。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch学习手册</title>
      <link href="/2022/01/17/ElasticSearch%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C/"/>
      <url>/2022/01/17/ElasticSearch%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C/</url>
      
        <content type="html"><![CDATA[<h1 align="center" style="color:pink">ElasticSearch学习手册</h1><h2 id="ElasticSearch初始入门"><a href="#ElasticSearch初始入门" class="headerlink" title="ElasticSearch初始入门"></a>ElasticSearch初始入门</h2><p><a href="https://www.elastic.co/cn/">ElasticSearch官方</a></p><p><img src="https://pic2.zhimg.com/80/v2-a714cddebcbd383263cb07033e24a5a2_720w.jpg?source=1940ef5c" alt="img"></p><h3 id="ES简介📚"><a href="#ES简介📚" class="headerlink" title="ES简介📚"></a>ES简介📚</h3><p>Elasticsearch 是一个分布式可扩展的实时搜索和分析引擎,一个建立在全文搜索引擎 <em>Apache Lucene</em>基础上的搜索引擎.</p><blockquote><ul><li>ElasticSearch对搜索引擎的操作都封装成restful的api，通过http请求就能对其进行操作。</li><li>分布式实时文件存储，实时分析。</li><li>可扩展到上百台服务器，处理PB级别的结构化或者非结构化数据。</li></ul></blockquote><h3 id="ES文件存储形式💽"><a href="#ES文件存储形式💽" class="headerlink" title="ES文件存储形式💽"></a>ES文件存储形式💽</h3><p>Elasticsearch是面向文档型数据库，一条数据在这里就是一个文档，用<em>JSON</em>作为文档序列化的格式</p><p><a href="https://developer.51cto.com/art/201904/594615.htm">漫画介绍👈</a></p><blockquote><table><thead><tr><th align="center">关系数据库</th><th align="center">DB库</th><th align="center">表</th><th align="center">行</th><th align="center">列</th></tr></thead><tbody><tr><td align="center">ES</td><td align="center">索引(Index)</td><td align="center">类型(Type)</td><td align="center">文档(Docments)</td><td align="center">字段(Fields)</td></tr></tbody></table><ul><li><p><strong>keyword</strong>与<strong>text</strong>的区别</p><blockquote><ul><li>keyword类型不会分词，根据字符串内容建立反向索引</li><li>Text 类型在存入时，会先分词，然后根据分词后的内容建立反向索引</li></ul></blockquote></li></ul></blockquote><p>ES核心概念</p><blockquote><ul><li><p>NRT</p><p>接近实时的搜索平台。</p></li><li><p>cluster<strong>集群</strong></p><p>由一个或者多个节点组织在一起，共同持有整个数据，一起提供索引和搜索。名字默认是“elasticsearch”</p></li><li><p>node<strong>节点</strong></p></li><li><p>index<strong>索引</strong></p></li><li><p>type<strong>类型</strong></p></li><li><p>document<strong>文档</strong></p></li><li><p>shards&amp;replicas<strong>分片和复制</strong></p></li></ul></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringStream入门教程学习</title>
      <link href="/2021/03/24/SpringStream%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E5%AD%A6%E4%B9%A0(%E6%9B%B4%E6%96%B0%E4%B8%AD%EF%BC%89/"/>
      <url>/2021/03/24/SpringStream%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E5%AD%A6%E4%B9%A0(%E6%9B%B4%E6%96%B0%E4%B8%AD%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="SpringStream入门教程学习-更新中"><a href="#SpringStream入门教程学习-更新中" class="headerlink" title="SpringStream入门教程学习(更新中)"></a>SpringStream入门教程学习(更新中)</h1><h2 id="springStream应用场景"><a href="#springStream应用场景" class="headerlink" title="springStream应用场景"></a>springStream应用场景</h2><ol><li>应用模型</li></ol><blockquote><p>Spring Cloud Stream由第三方中间件组成。应用间通信通过channel来完成，通道与外界代理的连接则是通过Binder实现。</p></blockquote><img src="D:\HexoLearning\SpringStream入门教程学习(更新中)\Snipaste_2021-01-08_11-29-40.png" alt="Spring Cloud Stream的应用模型" style="zoom: 67%;" /> <p>Binder可以理解为 提供Middleware操作方法的类</p>]]></content>
      
      
      
        <tags>
            
            <tag> SpringStream </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多线程，线程池</title>
      <link href="/2021/03/23/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%8F%96%E8%88%8D/"/>
      <url>/2021/03/23/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%8F%96%E8%88%8D/</url>
      
        <content type="html"><![CDATA[<center><h1 style="color:skyblue">线程池与多线程取舍</h1></center><h2 id="产生原因"><a href="#产生原因" class="headerlink" title="产生原因"></a>产生原因</h2><p>以前遇到的文件下载做法是重新写一个xxxExport</p><p>但是遇到一个更好的办法，直接使用我们select中的Page即可</p><p>具体方法如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//写入headers</span></span><br><span class="line">String[] headers = &#123;<span class="string">&quot;&quot;</span>,<span class="string">&quot;&quot;</span>,<span class="string">&quot;&quot;</span>&#125;; </span><br><span class="line"><span class="comment">//调用select中的函数，拿到Page</span></span><br><span class="line"><span class="type">Page</span> <span class="variable">page</span> <span class="operator">=</span> selectxxx(pageNo,PageSize);</span><br><span class="line"><span class="comment">//拿到Page中的总页数</span></span><br><span class="line"><span class="type">Page</span> <span class="variable">page2</span> <span class="operator">=</span> selectxxx(<span class="number">1</span>,(<span class="type">int</span>)page.getTotal());</span><br><span class="line"><span class="comment">//执行excelDownload</span></span><br><span class="line">excelDownLoad(response,headers,page2);</span><br></pre></td></tr></table></figure><p>因为循环内部出现查询和判断，执行效率极其慢，查一页是10s，查146条基本上是∞，所以果断采用了多线程进行提速，因为执行的数据不是相互依赖的数据，所以可以选择普通的多线程方法。</p><blockquote><p>前后踩得坑</p><ul><li><p>坑一：自己参照写了一个List来承接数据，然后进行处理</p><p>处理速度没有任何提升，甚至还需要自己多次修改。</p></li><li><p>坑二：使用线程池来加速处理</p><p>因为迭代器自身是一个类似于悲观锁的处理机制，在线程无法处理时就跳过处理，导致数据无法拿到</p></li><li><p>坑三：可能会导致OOM</p><p>这个暂时没法解决，为了速度牺牲内存</p></li></ul></blockquote><p>对于Page的下载，部分代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">excelDownLoad</span><span class="params">(HttpServletResponse response, String[] headers, Page page)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="comment">// 声明一个工作薄</span></span><br><span class="line">        <span class="type">XSSFWorkbook</span> <span class="variable">workbook</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">XSSFWorkbook</span>();</span><br><span class="line">        <span class="comment">// 生成一个表格</span></span><br><span class="line">        <span class="type">XSSFSheet</span> <span class="variable">sheet</span> <span class="operator">=</span> workbook.createSheet();</span><br><span class="line">        <span class="comment">// 设置表格默认列宽度为15个字节</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; headers.length; i++) &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">colWidth</span> <span class="operator">=</span> sheet.getColumnWidth(i) * <span class="number">2</span>;</span><br><span class="line">            <span class="keyword">if</span> (colWidth &lt; <span class="number">255</span> * <span class="number">256</span>) &#123;</span><br><span class="line">                sheet.setColumnWidth(i, colWidth &lt; <span class="number">3000</span> ? <span class="number">3000</span> : colWidth);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                sheet.setColumnWidth(i, <span class="number">6000</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">XSSFRow</span> <span class="variable">row</span> <span class="operator">=</span> sheet.createRow(<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">short</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; headers.length; i++) &#123;</span><br><span class="line">            <span class="type">XSSFCell</span> <span class="variable">cell</span> <span class="operator">=</span> row.createCell(i);</span><br><span class="line">            <span class="type">XSSFRichTextString</span> <span class="variable">text</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">XSSFRichTextString</span>(headers[i]);</span><br><span class="line">            cell.setCellValue(text);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//遍历集合数据，产生数据行</span></span><br><span class="line">        <span class="type">Iterator</span> <span class="variable">it</span> <span class="operator">=</span> page.getRecords().iterator();</span><br><span class="line">        <span class="type">int</span> <span class="variable">index</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">            index++;</span><br><span class="line">            row = sheet.createRow(index);</span><br><span class="line">            Map&lt;String, Object&gt; map = JSONObject.parseObject(JSONObject.toJSONString(it.next()), Map.class);</span><br><span class="line">            <span class="type">ImplProjectExcelVo</span> <span class="variable">objectValue</span> <span class="operator">=</span> JSONObject.parseObject(JSONObject.toJSONString(map), ImplProjectExcelVo.class);</span><br><span class="line">            <span class="comment">//利用反射，根据javabean属性的先后顺序，动态调用getXxx()方法得到属性值</span></span><br><span class="line">            Field[] fields = objectValue.getClass().getDeclaredFields();</span><br><span class="line">            <span class="comment">// 这里遍历fields 每个属性</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">short</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; fields.length; i++) &#123;</span><br><span class="line">                <span class="type">XSSFCell</span> <span class="variable">cell</span> <span class="operator">=</span> row.createCell(i);</span><br><span class="line">                <span class="type">Field</span> <span class="variable">field</span> <span class="operator">=</span> fields[i];</span><br><span class="line">                <span class="type">String</span> <span class="variable">fieldName</span> <span class="operator">=</span> field.getName();</span><br><span class="line">                <span class="type">String</span> <span class="variable">getMethodName</span> <span class="operator">=</span> <span class="string">&quot;get&quot;</span> + fieldName.substring(<span class="number">0</span>, <span class="number">1</span>).toUpperCase() + fieldName.substring(<span class="number">1</span>);</span><br><span class="line">                <span class="comment">// 提取getName() 这样方法</span></span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="type">Class</span> <span class="variable">tCls</span> <span class="operator">=</span> objectValue.getClass();</span><br><span class="line">                    <span class="type">Method</span> <span class="variable">getMethod</span> <span class="operator">=</span> tCls.getMethod(getMethodName,</span><br><span class="line">                            <span class="keyword">new</span> <span class="title class_">Class</span>[]&#123;&#125;);</span><br><span class="line">                    <span class="type">Object</span> <span class="variable">value</span> <span class="operator">=</span> getMethod.invoke(objectValue, <span class="keyword">new</span> <span class="title class_">Object</span>[]&#123;&#125;);</span><br><span class="line">                    <span class="comment">// 通过底层invoke 开启bug拿到值</span></span><br><span class="line">                    <span class="type">String</span> <span class="variable">textValue</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">                    <span class="comment">// 对于日期的值 转为日期 非日期的值当做字符串处理</span></span><br><span class="line">                    <span class="keyword">if</span> (value <span class="keyword">instanceof</span> Date) &#123;</span><br><span class="line">                        <span class="type">Date</span> <span class="variable">date</span> <span class="operator">=</span> (Date) value;</span><br><span class="line">                        <span class="type">SimpleDateFormat</span> <span class="variable">sdf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SimpleDateFormat</span>(<span class="string">&quot;yyyy-MM-dd HH:mm:ss&quot;</span>);</span><br><span class="line">                        textValue = sdf.format(date);</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="comment">//其它数据类型都当作字符串简单处理</span></span><br><span class="line">                        <span class="keyword">if</span> (value == <span class="literal">null</span>) &#123;</span><br><span class="line">                            textValue = <span class="string">&quot;&quot;</span>;</span><br><span class="line">                        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                            textValue = value.toString();</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                    cell.setCellValue(textValue);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        response.setCharacterEncoding(<span class="string">&quot;UTF-8&quot;</span>);</span><br><span class="line">        <span class="comment">// 设置contentType为excel格式</span></span><br><span class="line">        response.setContentType(<span class="string">&quot;application/vnd.ms-excel;charset=utf-8&quot;</span>);</span><br><span class="line">        <span class="comment">//默认Excel名称</span></span><br><span class="line">        response.setHeader(<span class="string">&quot;Content-disposition&quot;</span>, <span class="string">&quot;attachment;filename=&quot;</span> +</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">String</span>(<span class="string">&quot;表名&quot;</span>.getBytes(<span class="string">&quot;utf-8&quot;</span>), <span class="string">&quot;ISO-8859-1&quot;</span>) + <span class="string">&quot;.xlsx&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            response.flushBuffer();</span><br><span class="line">            workbook.write(response.getOutputStream());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IOException</span>(<span class="string">&quot;导出Excel出现严重异常，异常信息：&quot;</span> + e.getMessage());</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                workbook.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><ol><li><p>具体如何解决</p><blockquote><ol><li><p>建立线程池</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">ExecutorService</span> <span class="variable">pool</span> <span class="operator">=</span> Executors.newCachedThreadPool();</span><br></pre></td></tr></table></figure></li><li><p>使用计数器</p><p>CountDownLatch latch = new CountDownLatch(pageSize);</p></li></ol></blockquote></li><li><p>可以使用别的方法</p></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> TaskPool </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>四大算法--动态规划</title>
      <link href="/2021/03/13/Dynamic%20Programming/"/>
      <url>/2021/03/13/Dynamic%20Programming/</url>
      
        <content type="html"><![CDATA[<h1 id="四大算法–动态规划（Dynamic-Programming）"><a href="#四大算法–动态规划（Dynamic-Programming）" class="headerlink" title="四大算法–动态规划（Dynamic Programming）"></a>四大算法–动态规划（Dynamic Programming）</h1><h2 id="核心"><a href="#核心" class="headerlink" title="核心"></a>核心</h2><center style='color:skyblue;font-style:italic;'>Those who cannot remember the past are condemned to repeat it.</center><center style='color:red;font-style:italic;'>吃一堑长一智</center><h2 id="动态规划算法的两种形式"><a href="#动态规划算法的两种形式" class="headerlink" title="动态规划算法的两种形式"></a>动态规划算法的两种形式</h2><p>①<strong>自顶向下的备忘录法</strong></p><blockquote><p>Fibonacci数列</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fib</span>(<span class="params">n</span>):</span><br><span class="line"> <span class="keyword">if</span>(n &lt;= <span class="number">1</span>): </span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"> <span class="keyword">return</span> fib(n-<span class="number">1</span>)+fib(n-<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>采用的每层进行计算叠加</p><p>而当我们换用动态规划，每次计算的结果载入<code>备忘录(Memo)</code>中，当时用的时候直接使用。</p><p>但是这种方式额外产生了开销，这些开销是多次计算的不必要开销。</p></blockquote><p>②<strong>自底向上</strong></p><blockquote><p>自顶而下的方法，其实令很多内存空间多次使用，观察参与循环的只有n，n-1，n-2三项。</p><p>因此，我们可以自下而上计算，这样可以加快计算效率</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fib</span>(<span class="params">n</span>):</span><br><span class="line">    <span class="keyword">if</span>(n&lt;=<span class="number">1</span>): </span><br><span class="line">        <span class="built_in">print</span>(<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">1</span>)</span><br><span class="line">    sub1,sub2,i = <span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> i&lt;n-<span class="number">1</span>:</span><br><span class="line">        <span class="built_in">print</span>(sub2+sub1)</span><br><span class="line">        sub2,sub1=sub1+sub2,sub2</span><br><span class="line">        i+=<span class="number">1</span></span><br></pre></td></tr></table></figure></blockquote><h2 id="动态规划原理"><a href="#动态规划原理" class="headerlink" title="动态规划原理"></a>动态规划原理</h2><p>通过算法导论的例子，我们可以看出这类问题都涉及到重叠子问题，和最优子结构。</p><p><strong>①最优子结构</strong></p><p>​    我们观测一个问题的解结构包含其子问题的最优解，是否具有最优子结构性质，必须考察最优解用到的所有子问题。</p><p><strong>②重叠子问题</strong></p><p>​    斐波那契数列中，可以看到大量的重叠子问题，尤其是自顶而下的算法，反复求解，造成数据量计算的冗余。这时，Memo是一个不错的选择。</p><h2 id="动态规划中的经典模型"><a href="#动态规划中的经典模型" class="headerlink" title="动态规划中的经典模型"></a>动态规划中的经典模型</h2><h3 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h3><p>​    花和尚喝酒问题，过河问题，都可以用上动态规划思想。</p><blockquote><p><strong>花和尚喝酒：50里地，每走一里便要喝一坛酒，100坛酒能带回几坛</strong></p><p>50-100/3≈16，故应该为17坛。</p><p>假设路程是一来回再加上去的路程，那么我们可以计算出，每段路程消耗33坛酒，则容易算出，每段路程有16坛酒无法满足。</p><p>如果每段路走超过33.3里，就会导致酒喝光，无法步行。</p><p>我们取16里路，则会剩下52坛酒，再加上最开始100/3省掉的一坛酒，就是证明最后还可以有17坛酒</p></blockquote><p>在这里，我们的思维是抽象成线的。在数轴上多次计算。也可以用二分法不断得出结论。25不剩下酒，20能剩下10坛，15能剩下15坛，可以画出一个逼近曲线，必然存在一个保持平衡的点，使得50-x=x</p><h3 id="区间模型"><a href="#区间模型" class="headerlink" title="区间模型"></a>区间模型</h3><p>区间模型的状态表示一般为d[i][j]，表示区间[i, j]上的最优解，然后通过状态转移计算出[i+1, j]或者[i, j+1]上的最优解，逐步扩大区间的范围，最终求得[1, len]的最优解</p><blockquote><p><strong>给定一个长度为n（n &lt;= 1000）的字符串A，求插入最少多少个字符使得它变成一个回文串</strong></p><ol><li>在A[i]前面添加一个字符A[j]</li><li>在A[j]后面添加一个字符A[i]</li></ol><p>得到状态转移方程：<br>$$<br>d[ i ] [ j ] = min {d[ i+1 ][j],d[i][j+1]}+1<br>$$</p><p>空间复杂度为O(n^2),时间复杂度为O(n^2)</p></blockquote><h3 id="背包模型"><a href="#背包模型" class="headerlink" title="背包模型"></a>背包模型</h3><blockquote><p><strong>有N种物品（每种物品1件）和一个容量为V的背包。放入第 i 种物品耗费的空间是Ci，得到的价值是Wi。求解将哪些物品装入背包可使价值总和最大。</strong></p><ol><li>*f[i ，v]*表示前i种物品恰好放入一个容量为v的背包可以获得的最大价值。</li><li>决策为第i个物品在前i-1个物品放置完毕后，选择放还是不放</li></ol><p>状态转移方程为：<br>$$<br>f[ i ] [v] = min {f[ i-1 ][v],f[i-1][v-Ci]+Wi}<br>$$</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Dynamic Programming </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据入门学习(一)</title>
      <link href="/2021/01/28/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/"/>
      <url>/2021/01/28/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 align="center" style="color:skyblue">大数据入门学习</h1><h2 id="大数据概念"><a href="#大数据概念" class="headerlink" title="大数据概念"></a>大数据概念</h2><p>大数据（BIG DATA）是指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。</p><h2 id="大数据特点（5V）："><a href="#大数据特点（5V）：" class="headerlink" title="大数据特点（5V）："></a>大数据特点（5V）：</h2><blockquote><ul><li>VOLUME（大量）</li><li>VELOCITY（高速）</li><li>VARIETY（多样）</li><li>VALUE（低价值密度）</li><li>VERACITY（真实性）</li></ul></blockquote><h2 id="大数据学习历程："><a href="#大数据学习历程：" class="headerlink" title="大数据学习历程："></a>大数据学习历程：</h2><p><img src="https://pic2.zhimg.com/v2-b0a0cd2f6b5756474267a2090aecaabd_r.jpg" alt="preview"></p><p>Linux -&gt; Hadoop -&gt; Zookeeper -&gt; Hive -&gt; Flume -&gt; Kafka -&gt; HBase -&gt; Scala -&gt;（Storm）-&gt; Spark -&gt; 项目 - &gt; Flink</p><h4 id="Java语言的学习"><a href="#Java语言的学习" class="headerlink" title="Java语言的学习"></a>Java语言的学习</h4><blockquote><p>AOP，IOC，高并发，JVM</p></blockquote><h4 id="Linux系统-amp-Hadoop生态系统"><a href="#Linux系统-amp-Hadoop生态系统" class="headerlink" title="Linux系统&amp;Hadoop生态系统"></a>Linux系统&amp;Hadoop生态系统</h4><h6 id="Linux入门"><a href="#Linux入门" class="headerlink" title="Linux入门"></a>Linux入门</h6><blockquote><p> <a href="https://www.bilibili.com/video/av21303002?p=9">含shell</a>，<a href="https://www.bilibili.com/video/av68267149?p=5">不含shell</a></p><ol><li>常用基本命令</li><li>系统管理</li><li>Linux操作增强</li><li>Linux shell编程</li></ol></blockquote><h6 id="Hadoop生态（-）"><a href="#Hadoop生态（-）" class="headerlink" title="Hadoop生态（**）"></a>Hadoop生态（**）</h6><blockquote><p><a href="https://www.bilibili.com/video/av32081351?p=1">尚硅谷系列Hadoop</a>,<a href="https://www.bilibili.com/video/av64039568?from=search&seid=1820891664356324892">尚硅谷系列2019</a></p><p>Hadoop是一个分布式系统基础框架，用于主要解决海量数据的存储和海量数据的分析计算问题，也可以说Hadoop是后续整个集群环境的基础，很多框架的使用都是会依赖于Hadoop。主要是由HDFS、MapReduce、YARN组成。这个部分安装Hadoop，Hadoop的三个主要组成部分是重点，对他们的概念要理解出来，知道他们是做什么的，搭建集群环境，伪分布式模式和完全分布式模式的搭建，重要的是完全分布式的搭建，这些部分一定要自己动手实践，自己搭建集群，仔细仔细再仔细，Hadoop的NameNode，DataNode，YARN的启动关闭命令一定要知道，以及他们的启动关闭顺序要记住，不要搞混。</p><ol><li>分布式系统概述</li><li>Hadoop入门</li><li>Hadoop伪分布式</li><li>Hadoop全分布式</li><li>HDFS基本概念</li><li>HDFS的应用开发</li><li>HDFS的IO流操作</li><li>NameNode工作机制</li><li>DataNode工作机制</li></ol></blockquote><h6 id="Zookeeper入门"><a href="#Zookeeper入门" class="headerlink" title="Zookeeper入门"></a>Zookeeper入门</h6><blockquote><p><a href="https://www.bilibili.com/video/av53962808?from=search&seid=14867728339471861924">zookeeper</a>，<a href="https://www.bilibili.com/video/av32093417?from=search&seid=14867728339471861924">2019</a></p><ol><li>Zookeeper详解</li><li>HA框架原理</li><li>Hadoop-HA集群配置</li><li>MapReduce框架原理</li><li>Shuffle机制</li><li>Mapreduce案例一</li><li>Mapreduce案例二</li></ol></blockquote><h6 id="Hive入门（-）"><a href="#Hive入门（-）" class="headerlink" title="Hive入门（*）"></a>Hive入门（*）</h6><blockquote><p><a href="https://www.bilibili.com/video/av76061713?from=search&seid=6080018633047350271">Hive</a>，<a href="https://www.bilibili.com/video/av32097088?from=search&seid=14922409626561581253">Hive2</a>，<a href="https://www.bilibili.com/video/av65556024?from=search&seid=14922409626561581253">Hive2019</a></p><p>Hive是基于Hadoop的数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。Hive的安装，它的数据类型，以及它的数据定义、数据操作有较好的了解，怎么操作表（创建表、删除表，创建什么类型的表，他们有什么不同），怎么操作数据（加载数据，下载数据，对不同的表进行数据操作），对数据的查询一定要进行实践操作，以及对压缩方式和存储格式要有一些了解</p><ol><li>Hive DDL数据定义</li><li>Hive分区表</li><li>Hive分桶表</li><li>Hive查询</li><li>Hive的高级查询Join与排序</li><li>Hive的函数</li><li>Hive DML数据管理</li><li>Hive文件存储</li><li>Hive企业级调优</li><li>Hive企业级调优二</li><li>Hive企业级项目实战</li></ol></blockquote><h6 id="Flume详解"><a href="#Flume详解" class="headerlink" title="Flume详解"></a>Flume详解</h6><blockquote><p><a href="https://www.bilibili.com/video/av66126320?from=search&seid=4743678003250939296">Flume</a>,<a href="https://www.bilibili.com/video/av68376629?from=search&seid=15081053946655972416">Flume2</a>,<a href="https://www.bilibili.com/video/av65541678?from=search&seid=13455141829682550307">Flume2019</a></p><p>Flume是一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统。对于Flume，对它的组成架构，以及对Flume Agent的内部原理要理解清楚，Source、Channel、Sink一定要知道它们的各种类型以及作用，有哪些拓扑结构是常见常用的，例如一对一，单Source、多Channel、多Sink等,对Flume的配置文件一定要了解清楚</p><ol><li>Sqoop详解</li></ol></blockquote><h6 id="Hbase"><a href="#Hbase" class="headerlink" title="Hbase(*)"></a>Hbase(*)</h6><blockquote><p><a href="https://www.bilibili.com/video/av35356127?from=search&seid=759279005217475156">HBase</a>,<a href="https://www.bilibili.com/video/av65548392?from=search&seid=759279005217475156">HBase2019</a></p><p>HBase是一个分布式的、基于列存储的开源数据库。HBase适合存储PB级别的海量数据，也可以说HBase是很适合大数据的存储的，它是基于列式存储数据的，列族下面可以有非常多的列，列族在创建表的时候就必须指定。所以对HBase的数据结构要有一定的理解，特别是RowKey的设计部分</p><ol><li>Hbase的操作</li><li>Hbase整合</li><li>Hbase的实战和优化</li></ol></blockquote><h6 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka(*)"></a>Kafka(*)</h6><blockquote><p><a href="https://www.bilibili.com/video/av49920938?from=search&seid=12535568434906893507">Kafka</a>,<a href="https://www.bilibili.com/video/av65544753?from=search&seid=12535568434906893507">Kafka2019</a></p><p>Kafka是一个分布式消息队列，用来缓存数据的。比如说实时计算中可以通过Flume+Kafka对数据进行采集处理之后，Spark Streaming再使用Kafka相应的Topic中的数据，用于后续的计算使用。对于Kafka，要理解Kafka的架构，什么是Kafka，为什么需要Kafka，应用场景。基本的命令行操作要掌握，比如怎么创建删除Topic，怎么通过生产者生成数据，消费者怎么消费数据等基本操作</p></blockquote><h4 id="分布式计算框架"><a href="#分布式计算框架" class="headerlink" title="分布式计算框架"></a>分布式计算框架</h4><blockquote><ol><li><p>scala</p><blockquote><p>Scala主要重点包括：<strong>隐式转换和隐式参数、模式匹配、函数式编程</strong>。</p><p>推荐<a href="https://www.bilibili.com/video/BV11A411L7CK?from=search&seid=4249061453475483212">韩顺平</a></p></blockquote></li><li><p>Spark Core</p><blockquote><p>大数据架构体系</p><p>架构详解</p><p>Spark集群介绍</p><p>Spark集群配置</p></blockquote></li><li><p>Spark SQL</p></li><li><p>Spark Streaming</p></li><li><p>kafka</p></li><li><p>ElasticSearch，Kibana，Logstash</p></li><li><p>Redis</p></li></ol></blockquote><h4 id="大数据分析"><a href="#大数据分析" class="headerlink" title="大数据分析"></a>大数据分析</h4><blockquote><ol><li><p>Data Analyze数据分析基础</p></li><li><p>工作环境准备</p></li><li><p>数据可视化概念</p></li><li><p>Python机器学习</p></li><li><p>选择模型</p></li><li><p>构建树的过程</p><blockquote><ul><li>sklearn中决策树重要的参数</li><li>特征重要性得分</li></ul></blockquote></li><li><p>网格搜索</p><blockquote><ul><li>10折交叉验证</li><li>模型评价指标以及模型选择</li></ul></blockquote></li><li><p>sklearn中三类朴素贝叶斯算法</p><blockquote><ul><li><p>Bernoulli模型</p></li><li><p>Multinomial模型</p></li></ul></blockquote></li><li><p>颜色特征</p></li></ol></blockquote><h4 id="机器学习算法资料"><a href="#机器学习算法资料" class="headerlink" title="机器学习算法资料"></a>机器学习<a href="https://zhuanlan.zhihu.com/p/92760753">算法资料</a></h4><h2 id="大数据工程师技能要求"><a href="#大数据工程师技能要求" class="headerlink" title="大数据工程师技能要求"></a>大数据工程师技能要求</h2><p><img src="/../../../%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/v2-b3238d63d96cf09fb3a31035c969d468_720w.jpg" alt="大数据工程师技能"></p><p>每天3小时，每周每天10小时，3个月就会有（21×3+4×2×10）×3=423小时，差不多就是18天</p><h2 id="项目实战"><a href="#项目实战" class="headerlink" title="项目实战"></a>项目实战</h2><p>YouTube项目：<a href="https://www.bilibili.com/video/av46279488?from=search&seid=9082792700815539199">Hive</a></p><p>微博项目：<a href="https://www.bilibili.com/video/av47966656?from=search&seid=15571841572335097117">HBase</a></p><p>电商数据分析平台：<a href="https://www.bilibili.com/video/av51501619?p=25">Spark</a></p><p>电信客服系统：<a href="https://www.bilibili.com/video/av39312730?from=search&seid=9082792700815539199">Hadoop</a></p><p>滴滴系统：<a href="https://www.bilibili.com/video/av47297403?from=search&seid=2895912804952398963">Kafka+Storm</a></p><p>大数据离线平台：<a href="https://www.bilibili.com/video/av46287611?from=search&seid=9082792700815539199">Hadoop+Flume+Hive+HBase</a></p><p>电商数仓项目：<a href="https://www.bilibili.com/video/av55357971?from=search&seid=13797269418701982102">Hadoop+Zookeeper+Hive+Flume+Kafka+Spark</a></p><p>电商推荐系统（类似于电影推荐系统）：<a href="https://www.bilibili.com/video/av52027052?p=2">Hadoop+ZK+Flume+Kafka+Spark+Redis+MongoDB</a></p><p>电影推荐系统（2019版也有个一样的电影推荐系统，代码应该类似）：<a href="https://www.bilibili.com/video/BV1CJ411Q7L9?p=63">Hadoop+ZK+Flume+Kafka+Spark+Redis+MongoDB+ElasticSearch</a></p><p>基于阿里云搭建数据仓库（离线、实时）：ECS（日志生产服务器）+Flume+DataHub +MaxCompute/DataWorks +RDS（业务数据）+QuickBI</p><blockquote><p><a href="https://www.bilibili.com/video/BV1QJ411k76B?from=search&seid=5345818275548812087">离线</a></p><p><a href="https://www.bilibili.com/video/BV1pJ411r7Yk?from=search&seid=5345818275548812087">实时</a></p></blockquote><p>实时项目（电商数仓实时）：<a href="https://www.bilibili.com/video/BV1kA41147bS?from=search&seid=12616316689401784017">Hive+Kafka+Redis+Nginx+ElasticSearch+Canal</a></p><p>手机APP信息统计：<a href="https://www.bilibili.com/video/av51501685?from=search&seid=13797269418701982102">Hadoop+ZK+Flume+Kafka+Hive+HBase+Spark</a></p><p>在线教育项目：<a href="https://www.bilibili.com/video/av63729562?p=13">Hadoop+Flume+Kafka+Hive+MySQL+Spark</a></p><p>基于Flink的电商用户行为数据分析：<a href="https://www.bilibili.com/video/BV1gJ411Q72x?from=search&seid=5800841516085262679">Kafka+Flink</a></p><h2 id="大数据历程"><a href="#大数据历程" class="headerlink" title="大数据历程"></a>大数据历程</h2><p><img src="https://pic2.zhimg.com/80/v2-60e036c128aefe8bc313d21775dc45fd_720w.jpg" alt="大数据发展历程"></p><p>个人整理：</p><blockquote><ol><li><p>普遍认为<em>最伟大的时代变革点</em>是Google的<em>“三驾马车”</em>，2004年三篇重要论文的发表</p><blockquote><p>分布式文件系统 GFS</p><p>大数据分布式计算框架-MapReduce</p><p>NoSQL的数据库系统BigTable</p></blockquote><p>主要解决搜索引擎的两件事：<em>数据采集</em>，<em>数据搜索</em></p></li><li><p>Lucene（ElasticSearch的底层）项目创始人实现原型功能框架，类似于GFS和MapReduce，2006年Hadoop产品的前身被开发出来</p></li><li><p>Yahoo很快使用Hadoop，百度2007年也开始使用大数据存储与计算</p></li><li><p>2008年Hadoop正式成为Apache的顶级项目。与此同时，Yahoo自己基于MapReduce开发出Pig，类似于SQL语句的脚本语言，可直接生成MapReduce程序</p></li><li><p>Facebook为了数据分析也开发出一种新的数据分析工具–Hive，直接使用SQL语句进行大数据计算</p><p>至此，大数据的主要技术栈完成，包括HDFS，MapReduce，Pig，Hive.</p></li><li><p><em>责任单一Yarn</em>，拆分MapReduce的资源调度框架，执行框架，2012年开始运营Yarn</p></li><li><p>同年，伯克利的一位博士开发出Spark代替MapReduce，至此，MapReduce时代结束</p><blockquote><p>大数据计算根据数据分析方式不同，有两种类别。</p><p>一种是批处理计算，它主要是对某个时间段的数据进行计算，这种计算因为数据量大，非实时计算，历史积累的数据处理，也就是离线数据，又称为“离线数据”，代表性框架：MapReduce，Spark</p><p>另一种是对实时数据进行处理，又称为流式计算，“实时计算”，代表性框架：Storm，Flink，Spark Streaming</p><p>Flink既支持流式，又支持批处理</p></blockquote></li><li><p>2011年左右，HBase从Hadoop中拆分出去，成员又增加</p></li><li><p>机器学习，数据挖掘，数据分析技术的成熟</p><p><img src="https://pic2.zhimg.com/80/v2-81829c1243f5dcd1e0ffd4a1f8538be9_720w.jpg" alt="大数据的早期成型"></p></li></ol></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka 学习笔记(一)</title>
      <link href="/2021/01/13/Kafka%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0(%E4%B8%80)/"/>
      <url>/2021/01/13/Kafka%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0(%E4%B8%80)/</url>
      
        <content type="html"><![CDATA[<h1 align="center" style="color:skyblue">Kafka入门学习</h1><h2 id="Kafka初始学习"><a href="#Kafka初始学习" class="headerlink" title="Kafka初始学习"></a>Kafka初始学习</h2><p><a href="https://kafka.apachecn.org/">官方地址</a></p><p><img src="https://kafka.apachecn.org/images/logo.png" alt="img"></p><h4 id="Kafka介绍🎤"><a href="#Kafka介绍🎤" class="headerlink" title="Kafka介绍🎤"></a>Kafka介绍🎤</h4><p><strong>Kafka</strong>是最初由Linkedin公司开发，是一个<strong>分布式</strong>，<strong>分区的</strong>，<strong>多副本的</strong>，<strong>多订阅者</strong>，基于<strong>zk</strong>协调的分布式日志系统，是常用MQ系统的一个，常见于<code>web/nginx</code>日志，访问日志，消息服务等等.官网解释为<em>一个分布式流处理平台</em></p><h4 id="Kafka主要设计目标👍"><a href="#Kafka主要设计目标👍" class="headerlink" title="Kafka主要设计目标👍"></a>Kafka主要设计目标👍</h4><ul><li>以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。</li><li>高吞吐率，单机至少支持 **<u>100k/s</u>**消息传输。</li><li>支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。</li><li>同时支持离线数据处理和实时数据处理，可以在流式记录产生式就进行处理</li><li>支持在线水平扩展</li></ul><p>Kafka的消息传递模式是发布-订阅模式</p><h4 id="Kafka的优势☝"><a href="#Kafka的优势☝" class="headerlink" title="Kafka的优势☝"></a>Kafka的优势☝</h4><ol><li><p>解耦</p><blockquote><p>在数据处理过程中插入一个隐含的，基于数据的接口层，确保两端遵守同样的接口约束。</p><blockquote><p>类比污水处理器工序。</p></blockquote></blockquote></li><li><p>冗余</p><blockquote><p>确保处理数据时，发生失败的情况下，数据被持久化。雄安锡队列把数据进行持久化直到它们已经被完全处理。明确该消息已被处理完毕，然后进行删除。</p><blockquote><p>异常消息持久化。</p></blockquote></blockquote></li><li><p>扩展性和可恢复性</p><blockquote><p>扩展性</p><blockquote><p>解耦处理过程，增大消息入队和处理频率比较容易。</p></blockquote><p>可恢复性</p><blockquote><p>一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，即使一个消息在处理时挂掉，再次入队时仍可以被处理。</p></blockquote></blockquote></li><li><p>顺序保证和缓冲</p><blockquote><p>保证一个Partition内消息的有序性。</p><p>使用一个缓冲层来帮助任务最高效地执行–写入队列的处理尽可能的快速。</p></blockquote></li><li><p><em>削峰填谷</em></p></li><li><p>异步处理</p></li></ol><h4 id="性能比较👊"><a href="#性能比较👊" class="headerlink" title="性能比较👊"></a>性能比较👊</h4><ul><li><p>RabbitMQ</p><p>本身支持很多协议：AMQP，XMPP，SMTP，STOMP，十分重量级，更适合企业级开发</p><p>支持中心队列排序，负载均衡，数据持久化等</p></li><li><p>Redis</p><p>NoSQL,轻量级队列服务，新增HyperLogLog数据结构</p><p>采用的是发布订阅模式，需要开启多个客户端</p><p><a href="https://www.runoob.com/redis/redis-pub-sub.html">具体操作</a></p></li><li><p>ZeroMQ</p><p>ZeroMQ号称最快的消息队列系统，尤其针对大吞吐量的需求场景。但是ZeroMQ仅提供非持久性的队列，也就是说如果宕机，数据将会丢失</p></li><li><p>ActiveMQ</p><p>ActiveMQ是Apache下的一个子项目。 类似于ZeroMQ，它能够以代理人和点对点的技术实现队列。同时类似于RabbitMQ，它少量代码就可以高效地实现高级应用场景</p></li><li><p>Kafka/Jafka</p><p>Kafka是Apache下的一个子项目，是一个高性能跨语言分布式发布/订阅消息队列系统，而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。Kafka通过Hadoop的并行加载机制统一了在线和离线的消息处理。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统</p></li></ul><h4 id="术语解释📚"><a href="#术语解释📚" class="headerlink" title="术语解释📚"></a>术语解释📚</h4><p>Kafka有四个核心的API</p><p><img src="https://kafka.apachecn.org/10/images/kafka-apis.png" alt="img"></p><ul><li>The <a href="https://kafka.apachecn.org/documentation.html#producerapi">Producer API</a> 允许一个应用程序发布一串流式的数据到一个或者多个Kafka topic</li><li>The <a href="https://kafka.apachecn.org/documentation.html#consumerapi">Consumer API</a> 允许一个应用程序订阅一个或多个 topic ，并且对发布给他们的流式数据进行处理。</li><li>The <a href="https://kafka.apachecn.org/documentation/streams">Streams API</a> 允许一个应用程序作为一个<em>流处理器</em>，消费一个或者多个topic产生的输入流，然后生产一个输出流到一个或多个topic中去，在输入输出流中进行有效的转换。</li><li>The <a href="https://kafka.apachecn.org/documentation.html#connect">Connector API</a> 允许构建并运行可重用的生产者或者消费者，将Kafka topics连接到已存在的应用程序或者数据系统。比如，连接到一个关系型数据库，捕捉表（table）的所有变更内容。</li></ul><p>在Kafka中，客户端和服务器使用一个简单、高性能、支持多语言的 <a href="https://kafka.apache.org/protocol.html">TCP 协议</a>.</p><h5 id="Topics"><a href="#Topics" class="headerlink" title="Topics"></a>Topics</h5><p>核心概念:提供一串流式记录–topic</p><blockquote><p>因为采用的是发布订阅模式，可以拥有一个或者多个消费者来订阅它的数据。</p><p>每一个topic，Kafka集群都会维持一个分区日志。</p><img src="https://kafka.apachecn.org/10/images/log_anatomy.png" alt="img" style="zoom:50%;" /><p>每个分区都是有序且顺序不变的记录集，不断追加到结构化的<strong>commit log</strong>文件。</p><p>每个<strong>queue</strong>都有自己的**offset(偏移量)**来确定每一条记录。</p></blockquote><h5 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h5><blockquote><p>日志的分区partition(分布)在Kafka集群的服务器上。每个服务器在处理数据和请求时，共享这些分区，并且会在一配置的服务器上进行备份，确保容错性。</p><p>在处理负载均衡时，采用zk一样的算法，leader处理一切对partition的读写请求，followes则被动同步leader数据。</p></blockquote><h5 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h5><blockquote><p>生产者可以将数据发布到所选的topic中，生产者负责将记录分配到topic的哪一个 partition中。</p></blockquote><h5 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h5><blockquote><p>消费者使用一个消费组名称来进行标识，发布到topic中的每条记录被分配给订阅消费组中的一个消费者实例.消费者实例可以分布在多个进程中或者多个机器上</p><p>如果所有的消费者实例在同一消费组中，消息记录会负载平衡到每一个消费者实例.</p><p>如果所有的消费者实例在不同的消费组中，每条消息记录会广播到所有的消费者进程</p><img src="https://kafka.apachecn.org/10/images/log_consumer.png" alt="img" style="zoom:50%;" /><p>可以看到，数个消费者会组成一个消费组，便于扩展和容错。</p></blockquote><h5 id="High-Level"><a href="#High-Level" class="headerlink" title="High-Level"></a>High-Level</h5><blockquote><ul><li>生产者发送到特定topic partition 的消息将按照发送的顺序处理。 也就是说，如果记录M1和记录M2由相同的生产者发送，并先发送M1记录，那么M1的偏移比M2小，并在日志中较早出现</li><li>一个消费者实例按照日志中的顺序查看记录.</li><li>对于具有N个副本的主题，我们最多容忍N-1个服务器故障，从而保证不会丢失任何提交到日志中的记录.</li></ul></blockquote><h5 id="Stream批处理"><a href="#Stream批处理" class="headerlink" title="Stream批处理"></a>Stream批处理</h5><blockquote><p>Kafka 流处理不仅仅用来读写和存储流式数据，它最终的目的是为了能够进行实时的流处理。</p><p>在Kafka中，流处理器不断地从输入的topic获取流数据，处理数据后，再不断生产流数据到输出的topic中去。</p></blockquote><h2 id="启动使用"><a href="#启动使用" class="headerlink" title="启动使用"></a>启动使用</h2><p>（待更新）</p>]]></content>
      
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker 学习笔记</title>
      <link href="/2021/01/11/Docker%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/"/>
      <url>/2021/01/11/Docker%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 align ="center">Docker简易学习</h1><h2 id="Docker初始学习"><a href="#Docker初始学习" class="headerlink" title="Docker初始学习"></a>Docker初始学习</h2><p><img src="https://i.loli.net/2021/01/11/Nq4Vc9tlf5OpRdr.png" alt="image-20210111152302544.png"></p><h4 id="Docker的应用场景"><a href="#Docker的应用场景" class="headerlink" title="Docker的应用场景"></a>Docker的应用场景</h4><ul><li>web应用的自动化打包和发布</li><li>自动化测试集成和发布</li><li>部署服务型环境后台应用</li></ul><h4 id="Docker的优点"><a href="#Docker的优点" class="headerlink" title="Docker的优点"></a>Docker的优点</h4><blockquote><p>docker是一个用于开发，交付和运行应用程序的开放平台。</p><p>可以构建出虚拟环境，大大减少编写代码和在生产环境中运行代码之间的延迟。</p></blockquote><ol><li>快速交付应用</li><li>响应式部署和扩展</li><li>统一硬件上运行更多的工作负载</li></ol><h2 id="Docker架构"><a href="#Docker架构" class="headerlink" title="Docker架构"></a>Docker架构</h2><h4 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h4><blockquote><ul><li>镜像：相当于一个root文件系统</li><li>容器：镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。</li><li>仓库：代码控制中心，用来保存镜像</li></ul></blockquote><h2 id="Docker安装🔧"><a href="#Docker安装🔧" class="headerlink" title="Docker安装🔧"></a>Docker安装🔧</h2><h4 id="CentOS-Docker（CentOS7以上64位版本）"><a href="#CentOS-Docker（CentOS7以上64位版本）" class="headerlink" title="CentOS Docker（CentOS7以上64位版本）"></a>CentOS Docker（CentOS7以上64位版本）</h4><ul><li><p>官方脚本</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</span><br></pre></td></tr></table></figure><p>国内统一源daocloud</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -sSL https://get.daocloud.io/docker | sh</span><br></pre></td></tr></table></figure></li><li><p>手动安装</p><ul><li><p>先卸载旧版本</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ sudo yum remove docker \</span><br><span class="line">                  docker-client \</span><br><span class="line">                  docker-client-latest \</span><br><span class="line">                  docker-common \</span><br><span class="line">                  docker-latest \</span><br><span class="line">                  docker-latest-logrotate \</span><br><span class="line">                  docker-logrotate \</span><br><span class="line">                  docker-engine</span><br></pre></td></tr></table></figure></li><li><p>安装Docker仓库</p><ul><li><p>设置仓库</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo yum install -y yum-utils \</span><br><span class="line">  device-mapper-persistent-data \</span><br><span class="line">  lvm2</span><br></pre></td></tr></table></figure></li><li><p>设置源地址</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure></li></ul></li><li><p>安装Docker Engine-Community</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo yum install docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure></li></ul></li><li><p>启动Docker</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl start docker</span><br></pre></td></tr></table></figure></li><li><p>测试运行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run hello-world</span><br></pre></td></tr></table></figure></li></ul><h4 id="Windows-Docker（Not-Suggest）"><a href="#Windows-Docker（Not-Suggest）" class="headerlink" title="Windows Docker（Not Suggest）"></a>Windows Docker（Not Suggest）</h4><ul><li><p>Docker依赖于已经存在并运行的Linux内核环境</p></li><li><p>Docker Desktop是win10和MacOS上官方安装方式</p></li></ul><ul><li><p>开启Hyper-V</p><blockquote><p>Hyper-V 是微软开发的虚拟机，类似于 VMWare 或 VirtualBox，仅适用于 Windows 10。这是 Docker Desktop for Windows 所使用的虚拟机。</p><p>但是，这个虚拟机一旦启用，QEMU、VirtualBox 或 VMWare Workstation 15 及以下版本将无法使用！如果你必须在电脑上使用其他虚拟机（例如开发 Android 应用必须使用的模拟器），请不要使用 Hyper-V！</p></blockquote><p>在“应用于功能”中选择hyper-V</p><p>或者在超管的CMD中执行</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All</span><br></pre></td></tr></table></figure><p>安装<a href="https://hub.docker.com/?overlay=onboarding">Docker Desktop</a></p></li><li><p>检测是否成功</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run hello-world</span><br></pre></td></tr></table></figure></li></ul><h4 id="MacOS🍎"><a href="#MacOS🍎" class="headerlink" title="MacOS🍎"></a>MacOS🍎</h4><ul><li><p>使用HomeBrew安装</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ brew install --cask --appdir=/Applications docker</span><br></pre></td></tr></table></figure></li><li><p>手动下载</p><p><a href="https://download.docker.com/mac/edge/Docker.dmg">Edge版本</a>和<a href="https://download.docker.com/mac/stable/Docker.dmg">Stable版本</a>的Docker for Mac</p></li><li><p>启动终端后，通过命令检查Docker版本</p></li><li><p>镜像加速</p></li></ul><h4 id="Docker镜像加速🚀"><a href="#Docker镜像加速🚀" class="headerlink" title="Docker镜像加速🚀"></a>Docker镜像加速🚀</h4><ul><li><p>网易：<strong><a href="https://hub-mirror.c.163.com/">https://hub-mirror.c.163.com/</a></strong></p></li><li><p>阿里云：<strong>https://&lt;你的ID&gt;.mirror.aliyuncs.com</strong></p></li><li><p>七牛云加速器：<strong><a href="https://reg-mirror.qiniu.com/">https://reg-mirror.qiniu.com</a></strong></p></li><li><p>查看加速器是否生效</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker info</span><br></pre></td></tr></table></figure></li></ul><h4 id="Docker版本"><a href="#Docker版本" class="headerlink" title="Docker版本"></a>Docker版本</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker version</span><br></pre></td></tr></table></figure><h2 id="Docker的使用"><a href="#Docker的使用" class="headerlink" title="Docker的使用"></a>Docker的使用</h2><h4 id="Docker-Hello-World"><a href="#Docker-Hello-World" class="headerlink" title="Docker Hello World"></a>Docker Hello World</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run ubuntu:15.10 /bin/echo &quot;Hello world&quot;</span><br></pre></td></tr></table></figure><blockquote><p>参数解析:</p><blockquote><ul><li><strong>docker:</strong> Docker 的二进制执行文件。</li><li><strong>run:</strong> 与前面的 docker 组合来运行一个容器。</li><li><strong>ubuntu:15.10</strong> 指定要运行的镜像，Docker 首先从本地主机上查找镜像是否存在，如果不存在，Docker 就会从镜像仓库 Docker Hub 下载公共镜像。</li><li><strong>/bin/echo “Hello world”:</strong> 在启动的容器里执行的命令</li></ul></blockquote><p>解释为：Docker 以ubuntu15.10镜像创建一个新的容器，然后再容器里执行bin/echo  “Hello world”，然后输出结果。</p></blockquote><ul><li><p>交互式运行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -i -t ubuntu:15.10 /bin/bash</span><br></pre></td></tr></table></figure><blockquote><p>参数解析：</p><blockquote><ul><li><strong>-t:</strong> 在新容器内指定一个伪终端或终端。</li><li><strong>-i:</strong> 允许你对容器内的标准输入 (STDIN) 进行交互。</li></ul></blockquote><p>随后会进入容器内部，实现操作容器</p><p>可使用exit或者ctrl+D来退出</p></blockquote></li><li><p>启动容器</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d ubuntu:15.10 /bin/sh -c &quot;while true; do echo hello world; sleep 1; done&quot;</span><br></pre></td></tr></table></figure><p>启动一个容器，会返回一个容器ID</p><p>用 **docker ps **来查看运行容器</p></li><li><p>停止容器</p><p>使用<strong>docker stop</strong> id来停止容器</p></li></ul><h4 id="Docker的使用-1"><a href="#Docker的使用-1" class="headerlink" title="Docker的使用"></a>Docker的使用</h4><ul><li><p>获取容器</p><blockquote><p>如果我们本地没有 ubuntu 镜像，我们可以使用 docker pull 命令来载入 ubuntu 镜像</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull ubuntu</span><br></pre></td></tr></table></figure></blockquote></li><li><p>启动容器</p><p>使用ubuntu镜像启动一个容器，参数为一命令行模式进入该容器</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it ubuntu /bin/bash</span><br></pre></td></tr></table></figure><blockquote><p>参数说明：</p><blockquote><ul><li><strong>-i</strong>: 交互式操作。</li><li><strong>-t</strong>: 终端。</li><li><strong>ubuntu</strong>: ubuntu 镜像。</li><li><strong>/bin/bash</strong>：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 /bin/bash。</li></ul></blockquote></blockquote><p>使用<strong>docker start id</strong>来启动一个已经停止的容器。</p></li><li><p>后台进入和后台退出</p><p>指定容器运行模式 <strong>-d</strong> 且默认不会进入后台</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name ubuntu-test ubuntu /bin/bash</span><br></pre></td></tr></table></figure><p>进入 后台容器 中，退出容器不会导致容器停止</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it id /bin/bash</span><br></pre></td></tr></table></figure></li><li><p>删除容器</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rm -f id</span><br></pre></td></tr></table></figure><p>处理所有处于终止的容器</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker container prune</span><br></pre></td></tr></table></figure></li></ul><h4 id="Docker镜像的使用"><a href="#Docker镜像的使用" class="headerlink" title="Docker镜像的使用"></a>Docker镜像的使用</h4><ul><li><p>管理和使用本地Docker主机镜像</p><ul><li><p>展示镜像</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker images</span><br></pre></td></tr></table></figure></li><li><p>获取一个新的镜像</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull ubuntu:15.10</span><br></pre></td></tr></table></figure></li><li><p>拖取镜像</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull httpd</span><br></pre></td></tr></table></figure><p>拖取完就可以使用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run httpd</span><br></pre></td></tr></table></figure></li><li><p>删除镜像</p><p>使用 <strong>docker rmi</strong> 命令进行删除</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rmi hello-world</span><br></pre></td></tr></table></figure></li></ul></li><li><p>创建镜像</p><ul><li><p>构建镜像</p><p>使用 <strong>docker build</strong> 来创建一个新的镜像</p><ol><li><p>创建一个Dockerfile文件</p></li><li><p>使用 ** docker build -t images-name .</p><blockquote><ul><li><strong>-t</strong> ：指定要创建的目标镜像名</li><li><strong>.</strong> ：Dockerfile 文件所在目录，可以指定Dockerfile 的绝对路径</li></ul></blockquote></li></ol></li></ul></li></ul><h4 id="Docker-Dockerfile"><a href="#Docker-Dockerfile" class="headerlink" title="Docker Dockerfile"></a>Docker Dockerfile</h4><blockquote><p>Dockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。</p></blockquote><h4 id="Docker-Compose"><a href="#Docker-Compose" class="headerlink" title="Docker Compose"></a>Docker Compose</h4><blockquote><p>Compose 是用于定义和运行多容器 Docker 应用程序的工具。通过 Compose，您可以使用 YML 文件来配置应用程序需要的所有服务。然后，使用一个命令，就可以从 YML 文件配置中创建并启动所有服务。</p><blockquote><p>Compose 使用的三个步骤：</p><ul><li>使用 Dockerfile 定义应用程序的环境。</li><li>使用 docker-compose.yml 定义构成应用程序的服务，这样它们可以在隔离环境中一起运行。</li><li>最后，执行 docker-compose up 命令来启动并运行整个应用程序。</li></ul></blockquote></blockquote><h4 id="守护式容器🛡"><a href="#守护式容器🛡" class="headerlink" title="守护式容器🛡"></a>守护式容器🛡</h4><ul><li><p>启动：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d container_id</span><br></pre></td></tr></table></figure></li></ul><h2 id="暂时结尾😊"><a href="#暂时结尾😊" class="headerlink" title="暂时结尾😊"></a>暂时结尾😊</h2><p><a href="https://www.cnblogs.com/H4ck3R-XiX/p/12227485.html">docker 指令快速查询</a> 👈</p><p><a href="https://www.docker.org.cn/">docker中文网</a>👈</p><p><a href="https://blog.csdn.net/blissnmx/article/details/102922847">docker的简易框架，链接在此👇</a></p><img src="https://i.loli.net/2021/01/11/bBRy6rzLwOYcTxF.png" alt="docker-xmind.png" style="zoom:150%;" /><p>（后续待更新）</p>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
